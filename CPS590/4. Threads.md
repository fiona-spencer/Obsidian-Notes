- Two independent concepts
	- Resource ownership
	- Execution
- this has led to the development known as threads


# <font style="color:#96DED1"> 4.1 - Processes the Threads</font>

---

Resource Ownership
- Includes a virtual address space to hod the process image

Scheduling/execution
- Follows an execution path (trace) through one or more programs

- The unit of dispatching is referred to as a thread or lightweight process
- Unit of resource ownership is referred to as a process or task

# Multithreading
- Multithreading refers to the ability of an OS to support multiple, concurrent paths of execution within a single process
- MS-DOS uses a single-user process and single thread
- UNIX, support multiple user processes, but only one thread per processes
- A Java runtime environment uses multiple threads
- Windows, Solaris, and modern versions of UNIX, use multithreads
- In a multithreaded environment, a process is defined as the unit of resource allocation and a unit of protection

![[Pasted image 20250324124405.png|400]]

Processes:
- A virtual address space that holds the process image
- Protected access to processors, other processes, files, and I/O resources

Within a Process:
- A thread of execution
- A saved thread context when not running
- An execution stack
- Some per-thread static storage for local variables
- Access to the memory and resources of its process, shares with all other threads

- In a single-threaded process model there is no concept of a thread, the representation of a process includes its process control block, user address space, and kernel stack
- In a multithreaded environment, there is still a single process control block and user address space, but are separated stacks for each thread
	- Separate control blocks for each threads containing register values, priority, and other thread-related state information

![[Pasted image 20250324124605.png|400]]

- All the threads of a process share the state and resources of that process
- Benefits
	- Takes less time to create new threads in an existing processes
		- 10x faster in UNIX
	- Less time to terminate a thread than a process
	- Less time to switch between two threads within the same process
	- Threads enhance efficiency in communication

- File server
	- A new thread can be spawned for the file management program
	- Multiple threads within the same process can execute simultaneously
	- File servers must share data and coordinates their actions

- Threads on a Single-user multiprocessing system
	- Foreground and background work
	- Asynchronous processing
	- Speed of execution
	- Modular program structure

- Most of the information dealing with execution is maintained in thread-level data structures
- Suspension involved swapping the address space of one process from another
	- All threads are suspended at the same time
- Termination of a process terminated all threads within that process

# Thread Functionality
- Threads have execution states that may synchronize with one another

_THREAD STATES_
- The key states for a thread
	- Running
	- Ready
	- Blocked

4 Basic Thread Operations to Change state:
1) Spawn
2) Block
3) Unblock
4) Finish

- Threads that do not block the entire process give performance benefits
- Separate threads for each remote procedure call (RPC) results in a substantial speedup

![[Pasted image 20250324125525.png|500]]

- If on a uniprocessor, the requests must be generated sequentially and results processed in sequence
- Multiprogramming enables the interleaving of multiple threads within multiple processes

![[Pasted image 20250324125636.png|500]]


_THREAD SYNCHRONIZATION_
- All of the threads of a process share the same address space and other resources
- Alteration of a resources affects the environments of the other threads in the same process
- Necessary to synchronize the activities of all the threads

# <font style="color:#96DED1"> 4.2 - Types of Threads</font>

---
# User-Level and Kernel-Level Threads
- Two categories of thread implementation
	- User-Level Threads (ULTs)
	- Kernel-Level Threads (KLTs)
- _Kernel-level threads is also referred to as lightweight processes_


_USER-LEVEL THREADS_
- Work of the thread management is done by the application and the kernel is not aware
- 
![[Pasted image 20250324125956.png|400]]

- Any application can be programmed to be multithreaded using a threads library
- Threads library contains code for creating and destroying threads, for passing messages and data between threads
- Spawning a threads takes place in the user space and within a single process

![[Pasted image 20250324130309.png]]

- Application executing in thread 2 makes a system call that blocks B
- Process B goes into a Blocked states
- A clock interrupts passes control to the kernel
- Thread 2 has exhausted its time slice
- Places B in the Ready states
- Thread 2 has reached a point where it needs some action performed by thread 1
- Thread 2 enters a Blocked state
- Thread 1 transitions from Ready to Running

Advantages of ULTs instead of KLTs:
1. Thread switching does not require kernel-mode privileges
2. Scheduling can be application specific
3. ULTs can run on any OS

Disadvantages of ULTs instead of KLTs:
1. ULT executes a system call, and. all threads will be blocked
2. In a pure ULT, a multithreaded application cannot take advantage of multiprocessing

- Both disadvantages can be overcome by writing applications as multiple processes rather than multiple threads
- Jacketing is a technique to convert a blocking system call into a non-blocking system call

_KERNEL-LEVEL THREADS_
- All of the work of thread management is done by the kernel
- There is no thread management code in the application level
- Windows uses this approach
- Disadvantage
	- Transfer of control form one thread to another within the same process requires a mode switch to the kernel

![[Pasted image 20250324131234.png|500]]

- Orders of magnitude of different between ULT, and KLTs, and KLT, and processes
- User-level threads are much faster

_COMBINED APPROACHES_
- Bulk of the scheduling and synchronization of threads are within an application
- Multiple threads within the same application can run in parallel on multiple processors, and a blocking system call need not block the entire processes
- Solaris uses this approach

# Other Arrangements
- Resource allocation and dispatching unit have combined into a single concept of the processes

![[Pasted image 20250324131700.png|500]]

_MANY-TO-MANY RELATIONSHIP_
 - A domain is a static entity, consisting of an address space and "ports" through which messages may be sent and received
 - A thread is a single execution path, with an execution stack, processor state, and scheduling information

Ways to Implement this Application:
1. Entire program can be implemented as a single process
2. The main program and I/O subprogram can be implemented as two separate processes
3. Treat the main program and I/O subprogram as a single activity that is to be implemented as a single thread


_ONE-TO-MANY RELATIONSHIP_
- In distributed OS, there has been interest in concept of a thread as primarily an entity that can move among address spaces
	- Cloud OS, and its kernel, known as Ra
	- Emerald system
- A thread in Clouds is a unit of activity from the user's perspevtive
- A process is a virtual address space with an associated process control block
- Threads may move from one address space to another, and span computer boundaries
- As threads move, they must carry a certain amount of information, such as the controlling terminal, global parameters, and scheduling guidance

# <font style="color:#96DED1"> 4.3 - Multicore and Multithreading</font>

---
- The use of multicore system to support a single application with multiple threads (video game) raises issues of performance and application design


# Performance of Software on Multicore
- The potential performance benefits of a multicore organization depends on the ability to effectively exploit parallel resources available to the application

Amdahl's Law
![[Pasted image 20250324141922.png|400]]

- The law assumes a program in a fraction $(1-f)$ of the execution time involved code that is inherently serial, and a fraction $f$ that involved code that is infinity parallelizable with no scheduling overhead
- Multicore organizations are beneficial
- A small amount of serial code has a noticeable impact
- If only 10% of code is serial $(f=0.9)$, running the program on a multicore system with 8 processors yields a performance gain of a factor of only 4.7

![[Pasted image 20250324142205.png|300]]

- Software incurs overhead as a result of communication and distribution of work to multiple processors and cache coherence overhead
- The peak of number of processors is just before overhead becomes a burden to performance
- Reducing serial fraction within hardware architectures, OS, middleware, and database application software can help
- Servers can use parallel multicore organization, because they handle numerous relatively independent transactions in parallel
- Classes of applications benefit directly from the ability to scale throughput with the number of core
	- Multithreaded native applications
		- Lotus Domino
		- Siebel CRM
	- Multiprocess application
		- Oracle database
		- SAP
	- Java applications
		- Java Application Server
		- Websphere
	- Multi-instance application


![[Pasted image 20250324142617.png|400]]

# Application Example: Valve Game Software
- Valve is an entertainment and technology company that has developed a number of games, and Source engine
- Source engine software uses multithreading to exploit the power of multicore processor chips from Intel and AMD
- Threading granularity options
	- Coarse threading
	- Fine-grain threading
	- Hybrid threading
- Coarse threading could achieve up to twice the performance across two processors compared to executing on a single processor
- For real-world cases, the improvement was on the order of a factor of 1.2
- Fine-grained threading was difficult
- Hybrid threading approach was the most promising and would scale the best
- Scene rendering, can be organized into a number of threads so that the module can execute on a single processor but achieve greater performance

![[Pasted image 20250324143119.png|400]]

- Higher-level threads spawn lower-level threads as needed
- Key strategies for rendering
	- Construct scene rendering list for multiple scenes in parallel
	- Overlap graphics simulation
	- Compute character bone transformations for all characters in all scened in parallel
	- Allow multiple threads to draw in parallel

- Over 95% of the time, a thread is trying to read from a data set, and 5% is spend in writing to a data set
- Therefore, concurrency known as single-writer-multiple-reader model works effectively

# <font style="color:#96DED1"> 4.4 - Windows Process and Thread Management</font>

---
- An application consists of one or more processes
- Each process provides the resources needs to execute a program
- A thread is the entity within a process that can be scheduled for execution
- A job object allows groups of processes to be managed as a unit
- A thread pool is the collection of worker threads that efficiently execute asynchronously callbacks on behalf of the application
- A fiber is a unit of execution that must be manually scheduled by the application
- User-mode scheduling (UMS) is a lightweight mechanisms that applications can use to schedule their own threads

# Management of Background Tasks and Application Lifecycles
- From Windows 8 to 10, developers are responsible for managing the state of their individual application
- Windows Live Tiles give the appearance of applications constantly running
- In reality, they receive push notification and do not use system resources to display the dynamic content offered
- When the foreground application is in use, all other apps are suspended
- Application development relating to state changes is critical for Windows apps
	- Since starvation of background apps can occur
- A background task API is built to allow apps to perform small tasks while not in the foreground
- Push notification are template XML strings and managed by a cloud service known as Windows Notification Service (WNS)
- API will queue requests and process


# The Windows Process
Characteristics of Windows Processing
1) Windows processes are implemented as objects
2) A process can be created as a new process or as a copy of an existing process
3) An executable process may contain one or more threads
4) Both process and thread object have built-in synchronization capabilities


- The image illustrates the way process relates to the resources it controls or uses
- Each process is assigned a security access token, called the primary token of the process
- The token is used to validate the user's ability to secure objects, or perform functions
- Process includes an object table, with handles to other objects known to this process


![[Pasted image 20250324144335.png|400]]
# Process and Thread Objects
- Two types of Process-Related Objects in Windows:
	- Processes
	- Threads
- A process is an entry corresponding to a user job or application
- A thread is a dispatchable unit of work that executes sequentially and is interruptible
- A Windows process must contain at least one thread to execute
- The _thread processor affinity_ is the set of processors in a multiprocessor system that may execute this thread
- This set is equal to or a subset of the _process processor affinity_

![[Pasted image 20250324144843.png|600]]
![[Pasted image 20250324144858.png|600]]

# Multithreading
- Windows supports concurrency among processes because threads in different processes may execute concurrently
- A multithreaded process achieves concurrency without the overhead of using multiple processes
- Threads within the same process can exchange information through their common address space and have access to the shared resources of the process
- Threads in different processes can exchange information through shared memory
- An object-oriented multithreaded process is an efficient means of implementing a server application

# Thread States
An existing Windows threads is in one of 6 states
1) Ready
2) Standby
3) Running
4) Waiting
5) Transition
6) Terminated

![[Pasted image 20250331125058.png|500]]
# Support for OS Subsystems
- Process creation begins with a request for a new process from an application
- The application issues a create-process request to the corresponding protected sub-system, which passes the request to the Executive
- The Executive creates a process object and returns a handle for that object to the subsystem
- In case of Win32, a new process must always be created within an initial threads
- In the case of POSIX, threads are not supported, and subsystems obtain a thread for the new process from Windows

# <font style="color:#96DED1"> 4.5 - Solaris Thread and SMP Management</font>

---

- Solaris implement multilevel thread support designed to provide considerable flexibility in exploiting processor resources
# Multithreaded Architecture
Solaris uses 4 separate thread-related concepts:
1. Process
	1. User address space
	2. Stack
	3. Control block
2. User-level threads
3. Lightweight processes
4. Kernel threads

- There is always exactly one kernel thread for each LWP
- An LWP is visible within a process to the application, and bound to a single dispatchable kernel thread, and maintained within the kernel address space

![[Pasted image 20250331125823.png|500]]

# Motivation
- The 3 level thread structure (ULT, LWP, kernel thread) is used to provide a clean interface
- A defined ULT maps onto a LWP
- A LWP is bound to a kernel thread with one-to-one correspondence in execution states
- Concurrency and execution are managed at the level of the kernel thread
- An application has access to hardware through an API consisting of system calls
	- Read or write to a file, create a new process or thread, allocate memory

# Process Structure
Typical UNIX system:
- Process ID
- User ID
- Signal dispatch table
- File descriptor
- Memory map
- Process state structure

Solaris:
- Retains the UNIX basic structure
- But replaces the processor state block with a list of structures containing one data block for each LWP
- LWP elements:
	- LWP identifier
	- Priority
	- Signal mask
	- Saves values of user level registers
	- Kernel stack for this LWP
	- Resource usage and profiling data
	- Pointer to corresponding kernel thread
	- Pointer to the process structure

![[Pasted image 20250331130257.png|500]]

# Thread Execution
- States reflect the execution status of both the kernel thread and LWP that is bound to it
- Some kernel threads to not have a LWP

![[Pasted image 20250331130604.png|400]]

- RUN
	- The thread is runnable, ready to execute
- ONPROC
	- Thread is executing on a processor
- SLEEP
	- The thread is blocked
- STOP
	- The thread is stopped
- ZOMBIE
	- The thread has terminated
- FREE
	- Thread resources have been released and the thread is awaiting removal from the OS thread data structure


# Interrupts as Threads
- Most OS have two fundamental forms of concurrent activity
	- Processes
	- Interrupts
- Processes (or threads) cooperate with each other and manage the use of shared data structures
- Interrupts are synchronized by preventing their handling for a period of time
- Solaris unifies these two concepts into a single model, namely kernel threads
- Interrupts are converted to kernel threads
- This reduced overhead

Solaris Kernel Threads
1. Employs a set of kernel threads to handle interrupts
2. Kernel controls access to data structures and synchronizes among interrupts threads using mutual exclusion primitives
3. Interrupt threads are assigned higher priorities than all other types of kernel threads

- A pinned thread cannot move to another processor and its context is preserved
- Solaris threads provides significant performance compared to the traditional interrupt-handling strategy

# <font style="color:#96DED1"> 4.6 - Linux Process and Thread Management</font>

---
# Linus Tasks
- A process or task, in Linux is represented by a `task_struct` data structure
- The `task_struct` data structure contains information in a number of categories

1. State
2. Scheduling information
3. Identifiers (PID)
4. Interprocess communication (IPC)
5. Links
6. Times and timers
7. File system
8. Address space
9. Processor-specific context
10. Running
11. Interruptible
12. Uninterruptible
13. Stopped
14. Zombie

![[Pasted image 20250331131537.png|500]]


# Linux Threads
- Traditional UNIX systems support a single thread of execution per process, while modern UNIX systems typically provide support for multiple kernel-level threads per process
- Older versions of UNIX do not support multithreading, applications would need to be written with a set of user-level library function known as _pthreads (POSIX threads) libraries_
- A new process is created in Linux by copying the attributes of the current process
- A new process can be _cloned_ so it shares resources such as files, signal handlers, and virtual memory
- When the two processes share the same VM, they function as threads within a single processes
- In place of `fork()`, processes are create in linux using `clone()`
- This includes a set of flags as arguments

Clone flags:
- CLONE_NEWPID
	- Creates a new process ID namespace
- CLONE_PARENT
	- Caller and new task share the same parent process
- CLONE_SYSVSEM
	- Share System V SEM_UNDO semantics
- CLONE_THREAD
	- Inserts this process into the same thread group of the parent, if true it implicitly enforces CLONE_PARENT
- CLONE_VM
	- Shares the address space
- CLONE_FS
	- Shares the same filesystem information
- CLONE_FILES
	- Shares the same file descriptor table

# Linux Namespaces
- Associated with each process in Linux are a set of namespaces
- A namespace enables a process to have a different view of the system than other processes
- Namespaces and cgroups are the bases of Linux lightweight virtualization

6 Namespaces:
1) mnt
2) pid
3) net
4) ipc
5) uts
6) user

- Namespaces are create by the `clone()` system call
- A process can also create a namespace with the `unshare()` system call


_MOUNT NAMESPACE_
- A mount namespace provides the process with a specific view of the filesystem hierarchy, such that two processes with different mount namespaces see different filesystem hierarchies


_UTS NAMESPACE_
- The UTS (UNIX timesharing) is related to the uname Linux system call
- Returns the name and information about the current kernel, including nodename, which is the system name within some implementation defined network, and NIS domain name
- NIX (Network Information Service) is a standard scheme used on all UNIX systems
- System administrators can set up NIS client system from a single location and set similar configurations


_IPC NAMESPACE_
- Isolates certain interprocess communication (IPC), such as semaphores, POSIX message queues, and more


_PID NAMESPACE_
- Isolate the process ID space, so processes in different PID namespaces have have the same PID
- Used for Checkpoint/Restore In Userspace (CRIU)
- Freeze running application and checkpoint it to a hard drive

_NETWORK NAMESPACE_
- Provide isolation of the system resource associated with networking
- Each network namespace has its own device, IP address, IP routing table, port number, and so on
- A socket can belong to only one namespace


_USER NAMESPACE_
- Provides a container with its own set of UIDs, separate from the parent
- Clones process has access to and privileges of the parent process

_THE LINUX CGROUP SUBSYSTEM_
- cgroup and namespace subsystem, are the basis of lightweight process virtualization
- Docker, LXC, Kubernetes are based on both of them
- Provides resource management and accounting
- Handles resources such as CPU, network, memory, and more
- Need in embedded devices and servers, less in desktops


# <font style="color:#96DED1"> 4.7 - Android Process and Thread Management</font>

---

# Android Applications
- An Android application is software that implements an app
- Each application consisted of one or more instance of one or more of the 4 types of application
- Each component performs a distinct role and behaviour

4 Types of Android Components:
1. Activities
	1. A single screen visible to a user interface
2. Services
	1. Background operations
		1. Play music
		2. System services
3. Content providers
	1. Stored data in SQLite database, on the web, or any other persistent storage location
4. Broadcast receivers
	1. Responds to system-wide broadcast
		1. Low battery warning

- Each application runs on its own dedicate VM and own single process that encompasses the application an is VM
- This is referred to as the _sandboxing model_, isolated each application

![[Pasted image 20250331134406.png|200]]
# Activities
- Each activity is given a window to the user interface
- Can be full screen or popup window
- Activities are arranged in LIFO stack
- In order in which each activity is opened
- Back button will go to most recent foreground

_ACTIVITY STATES_
- When a new activity is launches, the application software performs series of API calls to the Activity Manager
- `onCreate()` does the static setup, including data structure initialization
- `onStart()` makes the activity visible
- `onResume()` passes control to the activity so user input goes to the activity
- The resumed state is referred to as _foreground lifetime_, activity is in front
- When user invokes the system goes to `onPause()`, and goes back to `onResume()` when use is finished interaction
- `onStop(0)` terminates activity
- An activity that is push to the background is `onStop()`

![[Pasted image 20250331134555.png|300]]


_KILLING AN APPLICATION_
- System can reclaim memory by killing one or more activities using `onDestroy()`

# Processes and Threads
- The default allocation of processes and threads on an application is a single process and a single thread
- All of the components of the application run on the single thread of the single process for that application

Levels of the Hierarchy (descending order of precedence)
1. Foreground process
2. Visible process
3. Service process
4. Background process
5. Empty process

# <font style="color:#96DED1"> 4.8 - Mac OS X Grand Central Dispatch</font>

---

- Mac OS X Grand Central Dispatch (GCD) provides a pool of available threads
- Designers can designate portions of applications, called blocks, that can be dispatched independently and run concurrently
- OS will provides as much concurrency as possible based on the number of cores available and the thread capacity
- A block is a simple extension to C or other languages

`x = ^{printf{"hellow world\n"};}`

- A block is denotes by a caret at the start of the function, enclosed in curly brackets
- Blocks enable programmers to encapsulate complex functions, with their arguments and data

![[Pasted image 20250331142122.png|150]]

- Blocks are scheduled and dispatched by queues
- Queues have three blocks

![[Pasted image 20250331142210.png|150]]

- Blocks are dispatched on FIFO basis
- Assigns F, G, then H
- Thread pools are automatically sized by the system to maximize the performance of the application using GCD

![[Pasted image 20250331142352.png|150]]

- The application can associate a single block and queue with an event source, such as a timer, network socket, or file descriptor
- Allows rapid response without the expense of polling

![[Pasted image 20250331142504.png|150]]

Example - Button on Document-Based Application

```c
- (Inaction) analyzeDocument: (NSButton *) sender
{
	NSDictionary *stats = [myDoc analyze]; //analyzes doc
	[myModel setDict:stats]; //updates application's internal state
	[myStatsView setNeedsDisplay:YES]; //updates stat view to new state
	[stats release];
}
```

- All functions in GCD begin with `dispatch()`
- The outer `dispatch_async()` call puts a task on a global concurrent queue
- This tells the OS that the block can be assigned to a separate concurrent queue
- The inner `dispatch_async()` call is encountered and directs the OS to put the following block of code at the end of the main


```c
- (IBAction) analyzeDocument: (NSButton *) sender
{dispatch_async(dispatch_get_global_queue(0, 0), ^{
	NSDictionary *stats = [myDoc analyze];
	dispatch_async(dispatch_get_main_queue(), ^{
		[myModel setDict:stats];
		[myStatsView setNeedsDisplay:YES];
		[stats release];
		})
	});
}
```


# <font style="color:#96DED1"> 4.9 - Summary</font>

---

- Some OS distinguish the concepts of process and thread
- User-level threads are efficient because a mode switch is not required to switch from one thread to another

# <font style="color:#96DED1"> 4.10 - Key Terms, Review Questions, and Problems</font>

---


