
- The central themes of OS design are concerned with the management of processes and threads
	- Multiprogramming
		- The management of multiple processes within a uniprocessor system
	- Multiprocessor
		- The management of multiple processes within a multiprocessor
	- Distributed processing
		- The management of multiple processes executing on multiple, distributed computer systems
		- Clusters

- Fundamental to all of these areas is **concurrency**
	- Communication among processes
	- Sharing of and competing for resources
	- Synchronization
	- Allocation of processor time

Concurrency in 3 different Contexts:
1) Multiple application
	1) Processor is shared among a number of applications
2) Structured applications
	1) Some application can be effectively programmed as a set of concurrent processes
3) OS structure
	1) Programs can be implemented as a set of processes or threads

- Basic requirement for support of concurrent processes is the ability to enforce mutual exclusion
- Approaches to mutual exclusion uses software that requires busy waiting
- Other uses OS or enforced by language compilers

3 Approaches to Mutual Exclusion
1. Semaphores
2. Monitors
3. Message passing

![[Pasted image 20250331144224.png]]

# <font style="color:#96DED1"> 5.1 - Mutual Exclusion: Software Applications</font>

---

- Software approaches usually assume elementary mutual exclusion at the memory access level
- Simultaneous access to the same location in main memory are serialized by a memory arbiter

# Dekker's Algorithm
- Dijkstra reported an algorithm for mutual exclusion for two processes, designed by mathematician Dekker

_FIRST ATTEMPT_
- Any attempt at mutual exclusion must rely on some fundamental exclusion mechanism in the hardware
- A global variable`turn` is equal to the number of processes
- Waiting process repeatedly reads the value of `turn` until it is allowed to enter its critical section
- This is known as **busy waiting** or **spin waiting** because the process can do nothing productive until it get permission to enter its critical section
- The waiting processes consume processor time (busy)
- After a process has gained access to its critical section and finished it must update the `turn` value
- This system guarantees mutual exclusion
- Processes must strictly alternate in their use of their critical section
- Coroutines are designed to be able to pass execution control back and forth between themselves
- This is inadequate to support concurrent processing

![](images/Pasted%20image%2020250401091011.png)


_SECOND ATTEMPT_
- Each process should have its own key to the critical section so that if one fails, the other can still access it
- `flag[0]` corresponding to P0 and `flag[1]` to P1
- Each process may examine the other's flag but not alter it
- The checking process sets its own flag to `true` and proceeds to its critical section
- When it leaves, it sets ifs flag to `false`

```c
enum boolean (false = 0; true = 1);
boolean flag[2] = 0, 0
```

- However, if a process fails inside its critical section or after setting its flag to `true` , then the other process is blocked
- This does not guarantee mutual exclusion


_THIRD ATTEMPT_
- Guarantees mutual exclusion
- Although if both processes set their flags to `true` before entering the while statement, causing deadlock


_FOURTH ATTEMPT_
- Each process sets its flag to indicate its desire to enter its critical section, but is prepared to reset the flag to defer to the other process
- This is close to the correct solution, but is still flawed
- Mutual exclusion is guaranteed

```
P0 sets flag[0] to true.
Pl sets flag[1] to true.
P0 checks flag[1].
Pl checks flag[0].
P0 sets flag[0] to false.
Pl sets flag[1] to false.
P0 sets flag[0] to true.
Pl sets flag[1] to true.
```

- This condition is livelock, where there are possible sequence of executions, but no process enters its critical section


_A CORRECT SOLUTION_
- Impose an order on the activities of the two processes to avoid the problem of "mutual courtesy"
- The variable `turn` is used for indicate which process has the right to insist on entering its critical region


```c
boolean flag [2];
int turn;

void P0()
{
	while (true){
		flag[0] = true;
		while (flag[1]){
			if (turn == 1){
				flag[0] = false;
				while (turn == 1)
				flag [0] = true;
			}
		}
		//Critial Section
		turn = 1;
		flag[0] = false;
	//remainder
	}
}

void P1(){
	while (true){
		flag[1] = true;
		while (flag[0]){
			if(turn == 0){
				flag[1] = false;
				while(turn == 0)
				flag[1] = true;
			}
		}
		//Cirital section
		turn = 0;
		flag[1] = false;
		//remainder
	}
}

void main(){
	flag[0] = false;
	flag[1] = false;
	turn = 1;
	parbegin(P0, P1);
}
```

- `parbegin(P1, P2, ..., Pn)` means
	- Suspend the execution of the main program
	- Initiate concurrent execution of procedures P1, P2, ..., Pn
	- When all of P1, P2, ..., Pn have finished, resume the main program


# Peterson's Algorithm
- Dekker's algorithm solves the mutual exclusion problem, but with a complex program
- Peterson has a simpler solution
- The global variable `flag` indicates the position of each process
- The global variable `turn` resolves simultaneity conflicts


```c
boolean flag[2];
int turn;

void P0(){
	while (true){
		flag[0] = true;
		turn = 1;
		while (flag[1] && turn == 1)
		//Critial section
		flag[0] = false;
		//remainder
	}
}

void P1(){
	while (true){
		flag[1] = true;
		turn = 0;
		while (flag[0] && turn == 0)
		//critial section
		flag[1] = false;
		//remainder
	}
}

void main(){
	flag[0] = false;
	flag[1] = false;
	parbegin (P0, P1);
}
```


# <font style="color:#96DED1"> 5.2 - Principles of Concurrency</font>

---
- In a single-processor multiprogramming system, processes are interleaved in time to yield the appearance of simultaneous execution
- In a multiprocess system, it is possible not only to interleave the execution of multiple processes, but also to overlap theme
- Difficulties
	- Sharing of global resources
	- OS to optimally manage the allocation of resources
	- Difficult to locate a programming error because results are typically not deterministic and reproducible

# A Simple Example

```c
void echo(){
	chin = getChar();
	chout = chin;
	putchar(chout);
}
```

Problem in a Single-Processor Multiprogramming System:
- Process P1 invokes the `echo` and is interrupted after `getchar` returns its value and stores it in `chin`, character x
- Process P2 is activated and invokes `echo`, which runs to conclusion, inputting and then displaying a the y character
- Process P1 is resumed, and x value has been overwritten in `chin` and lost
- `chin` contains y, which is transferred to `chout` and displayed

- Therefore, if x and y is pressed, only 2 y's are shown

Multiprocess System:
- P1 invokes `echo` and is interrupted by P2, x is stored in `chin`
- P2 invokes `echo`, P1 is suspended, P2 is blocked and becomes suspended awaiting the availability of the `echo` procedure
- P1 is resumed and complete `echo`, x is displayed, and removes the block on P2
- P2 is resumed, a `echo` print y

- It is necessary to protect shared global variables/resources

Multiprocessor System:
- P1 and P2 are both executing, each on a separate processor
- Both processes invoke the `echo` 
- The following event occur in parallel

![[Pasted image 20250331155454.png|300]]

- The result is that the character input to P1 is lost before being displayed
- P2 is displayed twice

Multiprocessor System (Exclusion):
- P1 and P2 are both executing, on a separate processes
- P1 invokes the `echo`, then P2
- P2 is blocked, until P1 is done

- Solution for all types of systems is to control access to the shared resource

# Race Condition

- A race condition occurs when multiple processes or threads read and write data items so that the final result depends on the order of execution of instructions in the multiple processes

Ex.1
- P1 and P2 share the global variable `a`
- P1 updates `a` to 1, and during execution, P2 changes it to `2`
- The two tasks are in a race to write variable `a`
- The "loser" of the race determines the final values

Ex.2
- P3 and P4 share global variables `b` and `c`, with values 1 and 2
- During execution, P3 executes the assignment `b = b + c`
- P4 executes `c = b + c`
- The final values of the two variables depend on the order in which the two processes execute
- If P3 executed first, b = 3, c = 5
- If P4 is executed first, b = 4, c = 3

# Operation System Concerns
- Concerns of concurrency
	- OS must be able to track processes (control block)
	- OS must allocate and deallocate resources for each active process
		- Processor time
		- Memory
		- Files
		- I/O devices
	- OS protect the data and physical resources of each process against unintended interference by other processes
	- Function and output of process is independent of the speed of execution


# Process Interaction

3 Possible Degrees of Awareness:
1. Process unaware of each other
	1. Multiprogramming on multiple independent processes
2. Process indirectly aware of each other
	1. I/O buffer
3. Processes directly aware of each other

![[Pasted image 20250331160523.png|500]]

_COMPETITION AMONG PROCESSES FOR RESOURCES_
- Resource include I/O devices, memory, processor time, and the clock
- There is not exchange if information between the competing processes
- Deadlock is when both processes are waiting for the other to finish
- Another problem is starvation, where some processes are overlooked and cannot be accessed

![[Pasted image 20250401111301.png|400]]

- There are $n$ processes to be executed concurrently
- Each process includes a critical section that operates on on the same resource Ra
- To enforce mutual exclusion, two function are provided
	- `entercritical`
	- `exitcritical`
- Each function takes as an argument the name of the resource

_COOPERATION AMONG PROCESSES FOR SHARING_
- Covers processes that interact with other processes without being explicitly aware of them
	- Shared variable, files, or databases
- Data coherence

```
P1:
 a = a + 1;
 b = b + 1;
P2:
 b = 2 * b;
 a = 2 * a;
```

- If the state is initially consistent, each process taken separately will leave the shared data in a consistent state

```
a = a + 1;
b = 2 * b;
b = b + 1;
a = 2 * a;
```

- At the end of this execution, the condition a = b no longer holds
- The arguments for `entercritical` or `exitcritical` could be a variable, a file, or any shared object


_COOPERATION AMONG PROCESSES BY COMMUNICATION_
- With communication processes participate in a common effort that links all of the processes
- Communication can be characterized as consisting of messages of some sort
- Since no critical data is being shared through message passing, mutual exclusion is not a control requirement
- However, deadlock and starvation are still present
	- In deadlock, two processes may may be blocks waiting for a message from each other
	- In starvation, three processes, where 2 are trying to message the same processes

# Requirements for Mutual Exclusion
1) Only one process at a time is allowed into its critical section, for processes with shared resources
2) A process that halts in its noncritical section must do so without interfering with other processes
3) No be possible for a process requiring access to a critical section to be delayed indefinitely: no deadlock or starvation
4) When no process is in a critical section, any process that requests entry to its critical section must be permitted to enter without delay
5) No assumptions are made about relative process speeds or number of processors
6) A process remains inside its critical section for a finite time only


# <font style="color:#96DED1"> 5.3 - Mutual Exclusion: Hardware Support</font>

---
# Interrupt Disabling
- In a uniprocessor system, concurrent processes cannot have overlapped execution, they can only be interleaves
- A process will continue to run until it invokes an OS service or until it is interrupted

```c
while (true){
	// Disable interrupt
	// Critical section
	// Enable interrupt
	// Ramainder
}
```

- This approach is not efficient and will not work in a multiprocessor architecture

# Special Machine Instructions
- In a multiprocessor configuration, several processors share access to a common main memory
- Therefore, there is no master/slave relationship
- Rather processor behave independently in a peer relationship
- During execution, access to the memory location is blocks for any other instructions referencing that location
	- RAYN86
	- STOM93

_COMPARE & SWAP INSTRUCTIONS_
- The `compare&swap` instruction, also called a compare and exchange instruction can be defined as

```c
int compare_and_swap(int *word, int testval, int newval){
	int oldval;
	oldval = *word
	if (oldval == testval) *word = newval;
	return oldval;
}
```

- This version of the instruction checks a memory location (\*word) against a test value (testval)
- The memory location's current value, is replace with newval, or is left unchanged
-  A old memory value is always returned
- This atomic instruction has two parts: **compare** and **swap**
- Another version returns a Boolean value, true if the swap occurred, false otherwise

![[Pasted image 20250401113510.png|500]]

- The only process that may enter its critical section is one that finds `bolt` equal to 0
- All other processes attempting to enter their critical section go into busy waiting mode
- When a process leaves its critical section, it resets bolt to 0


_EXCHANGE INSTRUCTIONS_

```c
void exchange(int *register, int *memory){
	int temp;
	temp = *memory;
	*memory = *register;
	*register = temp;
}
```

- The instruction exchange the contents of register with that of a memory location
- This is shown in 5.5 b)
- A shared variable bolt initialized to 0
- Each process uses a local variable key that that is set to 1
- The only process that may enter its critical section is one that finds bolt = 0

Exchange Algorithm:
![[Pasted image 20250401113938.png|200]]

- If bolt = 0, then no process it in its critical section
- If bolt = 1, then one process (that has a key = 1 value) is in its critical section

_PROPERTIES OF THE MACHINE-INSTRUCTION APPROACH_
- Advantages
	- Applicable to any number of processes on either a single or a multi- processor sharing main memory
	- Simple and easy to verify
	- Used to support multiple critical section
- Disadvantages
	- Bust waiting is employed
	- Starvation is possible
	- Deadlock is possible


# <font style="color:#96DED1"> 5.4 - Semaphores</font>

---

![[Pasted image 20250401114232.png]]

- Two or more processes can cooperate by means of simple signals, such that a process can be forced to stop at a specified place until it has received a specific signal
- For signalling, special variables called semaphores are used
- To transmit a signal via semaphore `s`, a process executes the primitive `semSignal(s)`
- To receive a signal a process executes the `semWait(s)`
- If the signal has now been transmitted, the process is suspended until the transmission takes place

Semaphore Values:
1. Initialized to a non-negative integer value
2. The `semWait` operation decrements the semaphore values
		1. When negative, the process executing `semWait` is blocked
3. The `semSignal` increments the semaphore value
	1. If the value is less than or equal to zero, then a process blocks by `semWait` is unblocked


- A semaphore begins with a zero or positive value
- The value equals the number of processes that can issue a wait and immediately continue to execute
- If the value is zero, either by initialization or a processes is being used, the next process to issue a wait is blocked, and the semaphore value goes negative
- Each subsequent wait drive the semaphore values future into negative
- Each signal unblocks one of the waiting processes

3 Consequences of Semaphores:
1) There is not way to know before a process decrements a semaphore whether is is blocked or not
2) After an increment, a semaphore and another process get woken up, there is not way to know which process will respond in a uniprocessor system
3) When you signal a semaphore, you do not know if another processor is waiting

- The `semWait` and `semSignal` primitives are assumed to be atomic
- A restricted version, is known as the **binary semaphore**, that only takes on the values 0 and 1
	- A binary is set to 0 or 1
	- The `semWaitB` checks the semaphore value, if 0, then the processes is blocks, if 1, then the value is changed to 0 and the process continues
- `semSignalB` checks to see if semaphore value is 0, if so, then is unblocked, if no processes are blocks, the value is change to 1

![[Pasted image 20250401115523.png|500]]

![[Pasted image 20250401115644.png|500]]
- A non binary semaphore is referred to as **counting semaphore** or a **general semaphore**
- The concept related to binary semaphores is **mutual exclusion lock (mutex)**
- A mutex is a programming flag used to grab and release an object
- When data are acquired that cannot be shares, or processing is started that cannot be performed simultaneously, the mutex is set to lock (typically zero)
- Mutex is unlocked when the data are no longer needed or routine is finished
- A mutex is where the process that locks the mutex (sets the value to zero) must also be the one to unlock it (set to 1)
- It is possible for one process to lock a binary semaphore and another one to unlock it
- For both counting and binary semaphores, a queue is used to hold processes waiting on the semaphore
- The fairest removal policy is FIFO; a semaphore that includes this is a **strong semaphore**
- One that does not specify the order in which processes are removed is a **weak semaphore**

![[Pasted image 20250401124850.png|500]]

- A, B, and C depend on a result from process D
1. A is running, B, C, D are ready (s = 1)
2. When s = 0, B runs and issues a `semWait` and is blocked, allowing D to run
3. B is in blocked and (s = -1), D issues a `semWait` when complete which unlocks B to the ready queue
4. D rejoins the ready queue and C begins to run
5. C is blocked when it issues a `semWait`
6. A, and B are also blocks
7. D resumes, and issues a `semSignal` which unblocked the queue, for C, A, and B to run

![[Pasted image 20250401125703.png|500]]

# Mutual Exclusion
- Each process has a critical section used to access the resource
- In each process, a `semWait(s)` is executed just before its critical section
- If the value of `s` is negative, the process is blocked
- If 1 then it is decremented to 0, and the processes enters its critical section

- Three processes (A, B, C) access a shared resource by a lock
- Process A executes a `semWait` and enters its critical section, s = 0
- B and C perform `semWait` but are blocked pending
- When A exits it performs a `semSignal`, B enters its critical section, followed by C

![[Pasted image 20250401130043.png|400]]

s.count >= 0
- is the number of processes that can execute `semWait`without suspension
s.count < 0
- The number of processes suspended in a queue


# The Producer/Consumer Problem
- There are one or more producers generating some type of data and placing these in a buffer
- There is a single consumer that is taking items out of the buffer one at a time
- The system is to constrained to prevent the overlap of buffer operation
- Only one agent (producer or consumer) may access the buffer at any one time

![[Pasted image 20250401130353.png|500]]

- The producer can generate items and store them in the buffer at its own pace
- The consumer must make sure do not read from an empty buffer
- The semaphore `delay` is used to force the consumer to `semWait` if the buffer is empty
- The producer is free to add to the buffer at any time
- The producer performs a `semSignalB (delay)` to alert the consumer of an empty buffer

![[Pasted image 20250401130713.png|300]]

Incorrect Binary Semaphore Solution
![[Pasted image 20250401130730.png|500]]

- When the consumer has exhausted the buffer, it needs to reset the delay semaphore so it will be forced to wait until the producer has places more items in the buffer
- An auxiliary variable is set in the consumer's critical section

![[Pasted image 20250401130937.png|400]]

Correct  Binary Semaphore Solution
![[Pasted image 20250401131038.png|500]]


![[Pasted image 20250401131216.png|400]]
![[Pasted image 20250401131236.png|400]]

Semaphore Solution (Infinite)
![[Pasted image 20250401131252.png]]


- When the buffer is finite, it is treated as a circular storage, and pointer values must be expressed modulo the size of the buffer
![[Pasted image 20250401131423.png|300]]


- The semaphore `e` has been added to keep track of the number of empty spaces

Semaphore Solution (Finite)
![[Pasted image 20250401131533.png|500]]


# Implementation of Semaphores
- `semWait` and `semSignal` operations must be atomic primitives
- A way to implement them is in hardware or firmware
- Only one process at a time may manipulate a semaphore, using software schemes of Dekker's or Peterson algorithm
- Another way is hardware-support for mutual exclusion
	- `compare&swap`

![[Pasted image 20250401131805.png|550]]


# <font style="color:#96DED1"> 5.5 - Monitors</font>

---

- The monitor is a programming language construct that provides equivalent functionality to that of semaphores and that is easier to control
- Implemented in Pascal, Modula-2, and Java
- Programmers can put a monitor lock on any object

# Monitor with Signal
- A monitor is a software module consisting of one or more procedures, an initialization sequence, and local data

Characteristics of a Monitor:
1. Local data variable are accessible only by the monitor's procedures and not externally
2. A process enters the monitor by invoking one of its procedures
3. Only one process may be executing in the monitor at a time

- A monitor supports synchronization by the use of **condition variables** that are contained within the monitor and accessible only within the monitor
- Condition variables are a special data type, and operated on two functions
	- `cwait(c)`
		- Suspend execution of the calling process on condition`c
		- The monitor is now available for use by another process
	- `csignal(c)`
		- Resume execution of some process blocked

- Monitor `wait` and `signal` are different than the ones used for semaphores
- If a process is in a monitor signals and no task is waiting on the condition variable, the signal is lost

![[Pasted image 20250401132420.png|400]]

- A process can enter the monitor by invoking any of its procedures
- The monitor has a single entry point that is guarded so that only one process can be in the monitor at a time
- The monitor module, `boundedbuffer`, controls the buffer used to store and retrieve characters
- Two condition variables (declared with cond)
	- _notfull_ is true then there is room to add at least one character to the buffer
	- _notempty_ is true when there is at least one character in the buffer
- A producer can add characters to the buffer only by means of the procedure append inside the monitor, the producer does not have direct access to the buffer
- In the case of monitors, the monitor construct itself enforces mutual exclusion

![[Pasted image 20250401141710.png]]

- A process exits the monitor immediately after executing the `csignal`
- If the `csignal` does not occur at the end of the procedure, in Hoare's proposal, the process issuing the signal is blocked to make the monitor available and place in a queue until the monitor is free
- The advantage that monitors have over semaphores is that all of the synchronization functions are confined to the monitor
- Therefore, it is easier to verify that everything is correct and to detect bugs


# Alternate Model of Monitors with Notify and Broadcast
- Hoare's definition of monitors requires that is there is at least one process in a condition queue, a process from that queue run immediately when another process issues a `csignal`

2 Drawbacks to this approach:
1) If the process issuing the `csignal` has not finished with the monitor, then two additional process switches are required: one to block this process, and another to resume it when the monitor becomes available
2) Process scheduling associated with a signal must be perfectly reliable

- In Mesa, the `csignal` primitive is replaced by `cnotify`, with the following interpretation
	- When a process executing in a monitor executes `notify(x)`, it causes the x condition queue to be notified

![[Pasted image 20250401142440.png]]

- The Mesa approach to monitors is less prone to error, and more module for program construction

# <font style="color:#96DED1"> 5.6 - Message Passing</font>

---

- When processes interact with one another, two fundamental requirements must be satisfied
	- Synchronization
	- Communication
- Message passing systems come in many forms
- Message passing requires a pair of primitives

```c
send (destination, message)
receive (source, message)
```

# Synchronization

- A process sends information in the form of a message to another process designated by a destination
- A process receives information by executing the receive primitive, indicating the source and the message

![[Pasted image 20250401142931.png|400]]

- Both sender and receiver can be blocking or nonblocking
- 3 Combinations
	- Blocking send, blocking receive
	- Nonblocking send, blocking receive
	- Nonblocking send, nonblocking receive

- The nonblocking `send` it more natural for concurrent programming tasks
- Blocking for `receive` is used to return a message to the sender

# Addressing
- Two categories of send and receive
	- Direct addressing
		- The `send` primitive includes a specific identifier of the destination process
		- The `receive` will have a designated sending processes
		- *Implicit addressing
			- The source parameter of the `receive` possesses a value returned when the receive operation has been performed
	- Indirect addressing
		- Messages are not sent directly from sender to receiver
		- Sent to a shared data structure consisting of queues that can temporarily hold messages
		- Queues are referred to as mailboxes
		- Decouples the send and receiver, allowing for more flexibiliy

Sender/Receiver Relationship
1) One-to-one
	1) Private communication
2) Many-to-one
	1) ) Client/server
	2) Mailbox is referred to as a port
3) One-to-many
	1) Message is broadcast to a set of processes
4) Many-to-many
	1) Multiple servers/multiple clients`

- the association of processes to mailboxes can be either static or dynamic
- Ports are often statically associated with a particular process
- Primitives such as `connect` and `disconnect` are used for this purpose

![[Pasted image 20250401144252.png|400]]

# Message Format
- The format of message depends on the objectives of the messaging facility and whether it runs on a single computer or on a distributed system
- Some OS use fixed-length messages to minimize processing and storage overhead
- The message is divided into two parts
	- Header
	- Body

![[Pasted image 20250401144454.png|200]]

# Queueing Discipline
- The simplest queuing discipline is FIFO, but this may not be sufficient if some messages are more urgent than others
- An alternative is to allow the speficifying of message priority, on the basis of message type or by designation by the sender
- Another way is to allow the receiver to inspect the message queue and select which message to receive next

# Mutual Exclusion
- Blocking receive and nonblocking send
- The mailbox is initialized to contain a single message with null content
- If the mailbox is empty, the process is blocked
- Once a process has the message, it performs it critical section then places the message back into the mailbox
- Message functions as a token that is passed from process to process

![[Pasted image 20250401144859.png|500]]

- If there is a message, it is delivered to only one process and the others are blocked
- If the message queue is empty, all processes are blocked, when a message is available, only one blocked processes is activated and given the message

- Bounded-buffer producer/consumer problem
- Two mailboxes arse used
- As the producer generates data, it is sent as messages to the mailbox `mayconsume`
- The size of the buffer is determined by the global variable `capacity`
- Initially the mailbox is null, the number of messages with shrink which each production and grows with each consumption


# <font style="color:#96DED1"> 5.7 - Readers/Writers Problem</font>

---
- The readers/writers problem is when a data area shared among a number of processes, and there are processes that only read or write to that data area

Conditions
1. Any number of readers may simultaneously read the file
2. Only one writer at a time may write to the file
3. If a writer is writing to the file, no reader may read it

- Readers are processes that are not required to exclude one another
- Writers are processes that are required to exclude all other processes

# Readers Have Priority
- The semaphore `wsem` is used to enforce mutual exclusion
- As long as one writer is accessing the shared data, no other writers or readers can access it
- The first reader uses `wsem` to allow multiple readers to not wait before entering
- The global variable, `readcount` is used to keep track of the number of readers, and the semaphore x is used to assure that the `readcount` is updated
- Writers are subject to starvation

![[Pasted image 20250401151410.png|600]]


# Writers Have Priority
- Writers
	- A semaphore `rsem` that inhibits all readers while there is at least one writer in the data area
	- A variable `writecount` that controls the setting of `rsem`
	- A semaphore y that controls the updating of `writecount`
- Reader use an additional semaphore
- A long queue must not be built on `rsem`, otherwise writers will not be able to jump the queue
- Only one reader is allowed to queue on `rsem`, with the additional queueing on semaphore z

![[Pasted image 20250401151738.png|400]]
![[Pasted image 20250401151726.png|600]]

- An alternative solution, which gives writers priority and which is implemented using message passing
- There is a controller process that has access to shared data area
- Other processes wishing to access send a request message to the controller, when granted access, they indicate a finish message when completed execution
- The controller has 3 mailboxes, one for each type of message that it may receive
	- `writerequest
	- `readrequest`
	- `finished

- The controller process services write request message before read to give priority
- `count` is used to indicate the maximum number of readers


# <font style="color:#96DED1"> 5.8 - Summary</font>

---
- When multiple processes are executing concurrently, either actually in the case of multiprocessor system or virtually in the case of a single-processor multiprogramming system, issues of conflict resolution and cooperation arise
- Mutual exclusion is a condition in which there is a set of concurrent processes, only one of which is able to access a given resource at any time



# <font style="color:#96DED1"> 5.9 - Key Terms, Review Questions, and Problems</font>

---

